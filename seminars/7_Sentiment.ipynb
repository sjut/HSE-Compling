{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8EIf8RGc7022"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sjut/HSE-Compling/blob/master/seminars/7_Sentiment.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "Ec9ls9EIzwn_",
    "outputId": "de94840c-adc2-442c-9b71-b511a9af3930"
   },
   "outputs": [],
   "source": [
    "!pip install innvestigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "cBt9Gi0PzwoK",
    "outputId": "34a66df4-b53b-4e56-841a-8f13c2fe2307"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "colab_type": "code",
    "id": "x3s8x5jkzwoO",
    "outputId": "45e5fd82-255f-4ef9-983f-29805df8ac46"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import keras.backend\n",
    "import keras.models\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "56mr43dU082W",
    "outputId": "1b9eb64e-35dc-4a0f-cba0-96a3330f98c8"
   },
   "outputs": [],
   "source": [
    "!wget http://vectors.nlpl.eu/repository/11/180.zip\n",
    "!unzip 180.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHnQNF-p7fcX"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/sjut/HSE-Compling/master/seminars/data/reviews_tok.txt\n",
    "!wget https://raw.githubusercontent.com/sjut/HSE-Compling/master/seminars/data/reviews_scores.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "Будем использовать кусочек данных с соревнования SentiRuEval.\n",
    "Они уже предобработаны (лемматизированы и размечены POS-тегами). Каждый текст - строчка из токенов *лемма_тег*.\n",
    "Оценки усреднены по трем аспектам, шкалированы от 1 до 10.\n",
    "Мы будем строить бинарную классификацию, поэтому будем считать оценки выше 5 положительными, а 5 и ниже — отрицательными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8_w4nq_zwoT"
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "with open(\"reviews_tok.txt\") as f:\n",
    "    for line in f:\n",
    "        texts.append(line.rstrip('\\r\\n').split())\n",
    "scores = []\n",
    "with open(\"reviews_scores.txt\") as f:\n",
    "    scores = list(map(lambda x: float(x.rstrip(\"\\r\\n\")), f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_VMvtg8nzwoX",
    "outputId": "206682c0-ed51-475f-9cda-b8e85049d930"
   },
   "outputs": [],
   "source": [
    "scores = np.array(scores)\n",
    "binary_scores = scores > 5.\n",
    "print(binary_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9DQSdoaazwod"
   },
   "outputs": [],
   "source": [
    "binary_scores = binary_scores.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1agAEQRgzwoi"
   },
   "outputs": [],
   "source": [
    "def max_length(texts):\n",
    "    return max(len(t) for t in texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "sGFo8BKP919y",
    "outputId": "c00d495c-2a11-474f-e049-f655215b4219"
   },
   "outputs": [],
   "source": [
    "print(len(texts))\n",
    "print(len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "Посчитайте $tf*idf$ для токенов и биграмм сначала на всем корпусе, а затем отдельно для положительных и отрицательных отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Выведем топ по tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Для положительных отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Для отрицательных отзывов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Возьмем представление в виде $tf*idf$ и попробуем обучить на нем классификатор.\n",
    "Будем использовать Randomm Forest, чтобы легко вытащить важность признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "X_train = vectorizer.fit_transform([\" \".join(t) for t in texts[:2000]]).toarray()\n",
    "y_train = binary_scores[:2000]\n",
    "clf.fit(X_train, y_train)\n",
    "y_test = binary_scores[2000:]\n",
    "X_test = vectorizer.transform([\" \".join(t) for t in texts[2000:]]).toarray()\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# А вот так можно посмотреть на самые важные признаки\n",
    "sorted(zip(vectorizer.get_feature_names(), clf.feature_importances_), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**: не очень утешительные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка тональности с помощью CNN\n",
    "\n",
    "В качестве входных представлений будем использовать word2vec для лемм с POS-тегами UD.\n",
    "Архитектура классификатора примерно воспроизводит описанную в [статье Arras et al. 2017](http://www.aclweb.org/anthology/W16-1601); а для визуализации воспользуемся библиотекой [iNNvestigate](https://github.com/albermax/innvestigate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "1bmDji9bzwoy",
    "outputId": "fc9748cb-b8e1-4179-a438-fd9e762649d9"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "w2v_model = KeyedVectors.load_word2vec_format('model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rrCyeyazwpV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "scores_train, scores_val, texts_train, texts_val = train_test_split(\n",
    "    binary_scores, texts[:2000], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJVzKjWHzwo-"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "MAX_LEN = max(max_length(texts_train), max_length(texts_val))\n",
    "\n",
    "def load_dataset(lines, embedding_dim, num_examples=None):\n",
    "    prep = lines[:num_examples]\n",
    "    vocab = Counter()\n",
    "    x_tensor = np.zeros((len(prep), MAX_LEN, embedding_dim))\n",
    "    for i, text in enumerate(prep):\n",
    "        for j, w in enumerate(text):\n",
    "            try:\n",
    "                x_tensor[i, j, :] = w2v_model[w]\n",
    "            except KeyError:\n",
    "                pass\n",
    "        vocab[w] += 1\n",
    "    return x_tensor, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3IaochrzwpF"
   },
   "outputs": [],
   "source": [
    "input_tensor_train, inp_vocab_train = load_dataset(texts_train, w2v_model.vector_size)\n",
    "input_tensor_val, inp_vocab_val = load_dataset(texts_val, w2v_model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eAck7cp8zwpY",
    "outputId": "571670f1-0bf1-4edc-e332-3ce370c08583"
   },
   "outputs": [],
   "source": [
    "w2v_model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "E7_x_oFtzwpi",
    "outputId": "67125808-44c7-495b-cb03-b774e680dd1d"
   },
   "outputs": [],
   "source": [
    "input_tensor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2KQJ48lrzwpk",
    "outputId": "fe23278f-403c-4eb4-fce6-d988013ffd7b"
   },
   "outputs": [],
   "source": [
    "scores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02SVGsB2zwpp"
   },
   "outputs": [],
   "source": [
    "embedding_dim = w2v_model.vector_size\n",
    "inp_vocab = inp_vocab_train + inp_vocab_val\n",
    "vocab_inp_size = len(inp_vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Картинка про плассификатор и оценку значимости входных слов ([источник](https://doi.org/10.1371/journal.pone.0181142.g001)):\n",
    "<img src=\"https://camo.githubusercontent.com/ba37f37fdbb90ccd76f1c4bf399e0cb8ddbc66f0/68747470733a2f2f692e696d6775722e636f6d2f595144665335502e706e67\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "uQiqdpcgzwpv",
    "outputId": "ec6c36df-f76a-4a2b-b3e5-4063677054c9"
   },
   "outputs": [],
   "source": [
    "from innvestigate.utils.tests.networks import base as network_base\n",
    "def build_network(max_len, voc_size, embedding_dim, output_n, activation=None, dense_unit=256, dropout_rate=0.25):\n",
    "    if activation:\n",
    "        activation = \"relu\"\n",
    "\n",
    "    net = {}\n",
    "    net[\"in\"] = keras.Input(shape=[1, max_len, embedding_dim])\n",
    "    net[\"conv\"] = keras.layers.Conv2D(filters=100, kernel_size=(1,2), strides=(1, 1), padding='valid')(net[\"in\"])\n",
    "    net[\"pool\"] = keras.layers.MaxPooling2D(pool_size=(1, max_len - 1), strides=(1,1))(net[\"conv\"])\n",
    "    net[\"out\"] = network_base.dense_layer(keras.layers.Flatten()(net[\"pool\"]), units=output_n, activation=activation)\n",
    "    net[\"sm_out\"] = network_base.softmax(net[\"out\"])\n",
    "\n",
    "\n",
    "    net.update({\n",
    "        \"input_shape\": [1, max_len, embedding_dim],\n",
    "        \"output_n\": output_n,\n",
    "    })\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = build_network(MAX_LEN, vocab_inp_size, embedding_dim, 2)\n",
    "model_without_softmax = keras.models.Model(inputs=net['in'], outputs=net['out'])\n",
    "model_with_softmax = keras.models.Model(inputs=net['in'], outputs=net['sm_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "e7Qr2TR8zwp0",
    "outputId": "91a417c5-0dfd-4950-e451-bb5e8c8d7abd"
   },
   "outputs": [],
   "source": [
    "model_without_softmax.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIwEjLbJzwp9"
   },
   "outputs": [],
   "source": [
    "def to_one_hot(y):\n",
    "    return keras.utils.to_categorical(y, 2)\n",
    "\n",
    "def train_model(model, epochs=20):\n",
    "    \n",
    "    x_train = np.expand_dims(input_tensor_train, axis=1)\n",
    "    y_train = to_one_hot(scores_train)\n",
    "    \n",
    "    x_val = np.expand_dims(input_tensor_val, axis=1)\n",
    "    y_val = to_one_hot(scores_val)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=256,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "colab_type": "code",
    "id": "cSKXBJo6zwqE",
    "outputId": "060bce50-77bd-4137-b980-0cc60b6e2c43"
   },
   "outputs": [],
   "source": [
    "train_model(model_with_softmax, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z3cmf_6lzwqO"
   },
   "outputs": [],
   "source": [
    "model_without_softmax.set_weights(model_with_softmax.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHS0bO03zwqW"
   },
   "outputs": [],
   "source": [
    "methods = ['gradient', 'lrp.z', 'lrp.alpha_2_beta_1', 'pattern.attribution']\n",
    "kwargs = [{}, {}, {}, {'pattern_type': 'relu'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "Y3aWRq0Gzwqa",
    "outputId": "b94be6b0-f559-4edc-9ef4-d08383fbbced"
   },
   "outputs": [],
   "source": [
    "import innvestigate\n",
    "analyzers = []\n",
    "\n",
    "for method, kws in zip(methods, kwargs):\n",
    "    analyzer = innvestigate.create_analyzer(method, model_without_softmax, **kws)\n",
    "    analyzer.fit(np.expand_dims(input_tensor_train, axis=1), batch_size=256, verbose=1)\n",
    "    analyzers.append(analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WLSLuolEzwqf"
   },
   "outputs": [],
   "source": [
    "def analyze_scores(X, Y, ridx):\n",
    "    max_len = max_length(input_tensor_train)\n",
    "\n",
    "    analysis = np.zeros([len(analyzers), 1, max_len])\n",
    "    x, y = X[ridx], Y[ridx]\n",
    "    t_start = time.time()\n",
    "    x = x.reshape((1, 1, max_len, embedding_dim))\n",
    "    presm = model_without_softmax.predict_on_batch(x)[0] #forward pass without softmax\n",
    "    prob = model_with_softmax.predict_on_batch(x)[0] #forward pass with softmax\n",
    "    y_hat = prob.argmax()\n",
    "  \n",
    "    for aidx, analyzer in enumerate(analyzers):\n",
    "        a = np.squeeze(analyzer.analyze(x))\n",
    "        a = np.sum(a, axis=1)\n",
    "        analysis[aidx] = a\n",
    "    t_elapsed = time.time() - t_start\n",
    "    print('Review %d (%.4fs)'% (ridx, t_elapsed))\n",
    "    return analysis, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "g55veSIp3BZV",
    "outputId": "e358a30e-4f3d-4c35-f406-3eba395c77c3"
   },
   "outputs": [],
   "source": [
    "analyze_scores(input_tensor_train, scores_train, 97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9Ysv32z3kjn"
   },
   "outputs": [],
   "source": [
    "def plot_text_heatmap(words, scores, title=\"\", width=5, height=0.2, verbose=0, max_word_per_line=10):\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    \n",
    "    ax = plt.gca()\n",
    "\n",
    "    ax.set_title(title, loc='left')\n",
    "    tokens = words\n",
    "    if verbose > 0:\n",
    "        print('len words : %d | len scores : %d' % (len(words), len(scores)))\n",
    "\n",
    "    cmap = plt.cm.ScalarMappable(cmap=cm.bwr)\n",
    "    cmap.set_clim(0, 1)\n",
    "    \n",
    "    canvas = ax.figure.canvas\n",
    "    t = ax.transData\n",
    "\n",
    "    # нормализация:\n",
    "    # - отрицательные оценки [0, 0.5]\n",
    "    # - положительные оценки (0.5, 1]\n",
    "    normalized_scores = 0.5 * scores / np.max(np.abs(scores)) + 0.5\n",
    "    \n",
    "    if verbose > 1:\n",
    "        print('Raw score')\n",
    "        print(scores)\n",
    "        print('Normalized score')\n",
    "        print(normalized_scores)\n",
    "\n",
    "    loc_y = -0.2\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        *rgb, _ = cmap.to_rgba(normalized_scores[i], bytes=True)\n",
    "        color = '#%02x%02x%02x' % tuple(rgb)\n",
    "        \n",
    "        text = ax.text(0.0, loc_y, token,\n",
    "                       bbox={\n",
    "                           'facecolor': color,\n",
    "                           'pad': 5.0,\n",
    "                           'linewidth': 1,\n",
    "                           'boxstyle': 'round,pad=0.5'\n",
    "                       }, transform=t)\n",
    "\n",
    "        text.draw(canvas.get_renderer())\n",
    "        ex = text.get_window_extent()\n",
    "        \n",
    "        # переходим на другую строчку, если слишком много слов\n",
    "        if (i+1) % max_word_per_line == 0:\n",
    "            loc_y = loc_y -  2.5\n",
    "            t = ax.transData\n",
    "        else:\n",
    "            t = transforms.offset_copy(text._transform, x=ex.width+15, units='dots')\n",
    "\n",
    "    if verbose == 0:\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "NizGgzIK5iTe",
    "outputId": "db293154-f5eb-4be0-adbe-25da457e8e4d"
   },
   "outputs": [],
   "source": [
    "a, y_pred = analyze_scores(input_tensor_train, scores_train, 100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "cypXsrHU52Wq",
    "outputId": "55cc8dd0-9b06-4b7b-859a-a049347da8a4"
   },
   "outputs": [],
   "source": [
    "print(\" \".join(texts_train[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "z9KU31JG5jxM",
    "outputId": "c41ac3f0-e9b0-43d8-fb1c-526e1ed05f37"
   },
   "outputs": [],
   "source": [
    "a[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "m3OfowS43tIa",
    "outputId": "11ebecfc-7f7d-4881-a3be-6c6b12fa4058"
   },
   "outputs": [],
   "source": [
    "plot_text_heatmap(\n",
    "    texts_train[100],\n",
    "    a[0][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "colab_type": "code",
    "id": "t9_8U_B_5Weo",
    "outputId": "db9721ec-9d3a-4188-a31b-43ad89f48d72"
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "words = texts_val[idx]\n",
    "    \n",
    "print('Review(id=%d): %s' % (idx, ' '.join(words)))\n",
    "y_true = scores_val[idx]\n",
    "a, y_pred = analyze_scores(input_tensor_val, scores_val, idx)\n",
    "\n",
    "print(\"Pred class : %d %s\" %\n",
    "      (y_pred, '✓' if y_pred == y_true else '✗ (%d)' % y_true)\n",
    "      )\n",
    "                            \n",
    "for j, method in enumerate(methods):\n",
    "    plot_text_heatmap(words, a[j].reshape(-1), title='Method: %s' % method, verbose=0)\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EabQvzhK62m7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "7_Sentiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
